{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Colab Badge Link](https://img.shields.io/badge/open-in%20colab-blue)](https://colab.research.google.com/github/Glasgow-AI4BioMed/tutorials/blob/main/candidate_generation_for_entity_linking.ipynb)\n",
        "\n",
        "# Candidate Generation for Entity Linking\n",
        "\n",
        "This notebook demonstrates a few ways that you can find candidates from a list of terms when trying to do [entity linking](https://en.wikipedia.org/wiki/Entity_linking)."
      ],
      "metadata": {
        "id": "GQ_G1CDPEPU5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Definition\n",
        "\n",
        "We have a mention of an entity in some text (e.g. 'n-sclc'). We're trying to figure out which entity it is referring to."
      ],
      "metadata": {
        "id": "hfddin7uEL6I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuefgjTuAcot"
      },
      "outputs": [],
      "source": [
        "mention_text = 'n-sclc'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a knowledgebase containing lots of entities (e.g. drugs, diseases, etc). Common knowledge bases include UMLS, MeSH, Disease Ontology, etc. The knowledgebase has lots of terms with their names, and possibly with additional aliases.\n",
        "\n",
        "Let's make up a mini-list of names from our knowledgebase that we want to search."
      ],
      "metadata": {
        "id": "9YXgbrRybC0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_space = [\n",
        "    'Lung cancer',\n",
        "    'NSCLC',\n",
        "    'Pancreatic cancer',\n",
        "    'Glioblastoma multiforme',\n",
        "    'Retinoblastoma',\n",
        "    'breast cancer',\n",
        "    'Basal cell carcinoma',\n",
        "    'Squamous cell carcinoma',\n",
        "    'Fibroma'\n",
        "]"
      ],
      "metadata": {
        "id": "Pzwys7-MAvyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Task:** We want an short ordered list of candidates that best match our target ('n-sclc'). *The right answer is most likely NSCLC for this*.\n",
        "\n",
        "The candidate list can then be used in the next stage of an information extraction pipeline. We might pick the top candidate as the one we'll use. Or we might use a second stage that will use another approach to score the candidates and decide which one seems the most plausible.\n"
      ],
      "metadata": {
        "id": "0vtLYQ_-bSJu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using text distance metrics\n",
        "\n",
        "We could use the [textdistance library](https://pypi.org/project/textdistance/) and calculate distances between our `mention_text` and every entry in the search space.\n",
        "\n",
        "First, install it:"
      ],
      "metadata": {
        "id": "fxMnFMILEXfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textdistance"
      ],
      "metadata": {
        "id": "Cic5yDrmZDEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`textdistance` contains a few options you could try. Let's go with the [Levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance) to calculate the number of edits needed to change one string into another:"
      ],
      "metadata": {
        "id": "czqFVNf0bnu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textdistance\n",
        "\n",
        "textdistance.levenshtein('abc', 'bcd')"
      ],
      "metadata": {
        "id": "mUv4i-DPb0dF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now iterate through every option in the search space and calculate a distance metric. We'll lowercase everything for this too."
      ],
      "metadata": {
        "id": "qCeVs59Ab1Zq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scored_candidates = []\n",
        "for candidate in search_space:\n",
        "  score = textdistance.levenshtein(mention_text.lower(), candidate.lower())\n",
        "  scored_candidates.append( (score, candidate) )"
      ],
      "metadata": {
        "id": "9qMYCBA9A8jN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sort all the options and get the top five."
      ],
      "metadata": {
        "id": "qGo2kmfQcDtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scored_candidates = sorted(scored_candidates, key=lambda x: x[0])\n",
        "scored_candidates[:5]"
      ],
      "metadata": {
        "id": "m0wHphI4EsdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cool. Our **correct** answer is scored highest.\n",
        "\n",
        "**Note:** This may be a fairly slow method if there are a lot of comparisons."
      ],
      "metadata": {
        "id": "_EAEgRclcJBD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Character N-Grams Similarity\n",
        "\n",
        "Another approach is to use character n-grams. 3-grams is a good option and can be done with scikit-learn. Let's create a vectorizer to do this:"
      ],
      "metadata": {
        "id": "xE2EZ0qiE4xN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(analyzer='char', # Work at the character-level (not token-level)\n",
        "                             ngram_range=(3,3), # Tell it to use trigrams\n",
        "                             norm='l2', # Tell it to normalize the vectors\n",
        "                             lowercase=True)"
      ],
      "metadata": {
        "id": "7m2fUidYBI71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then fit the vectorizer with the texts of all our possible options (the `search_space`)."
      ],
      "metadata": {
        "id": "oJTn7urAc_YZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_vectors = vectorizer.fit_transform(search_space)"
      ],
      "metadata": {
        "id": "ecuL6Mw4FHV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see what the vectorizer is doing by applying it to some text with `transform` and then running `inverse_transform`. It gets back our trigrams:"
      ],
      "metadata": {
        "id": "AtXqIYM5dDbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.inverse_transform(vectorizer.transform(['cancer']))"
      ],
      "metadata": {
        "id": "eH0PIJQCc6Kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can create a vector"
      ],
      "metadata": {
        "id": "5bgCxvfRdKz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mention_vector = vectorizer.transform([mention_text])\n",
        "mention_vector"
      ],
      "metadata": {
        "id": "NzdNfcIOFN68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we want to calculate the cosine similarity between our `mention_vector` and the `search_vectors`. All the vectors have already been normalized, so the cosine similarity is a dot product as below."
      ],
      "metadata": {
        "id": "YFW6PBrCdWd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = search_vectors.dot(mention_vector.T)\n",
        "scores = scores.toarray().squeeze().tolist() # Convert it to a 1D python list"
      ],
      "metadata": {
        "id": "QsJvtyLdFRw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the scores. Only one of them is non-zero:"
      ],
      "metadata": {
        "id": "_AylQef0eHp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "id": "SvkLeHVUFWXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can pair of the scores with all the possible options from the `search_space`."
      ],
      "metadata": {
        "id": "W213nfDWeLHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scored_candidates = list(zip(scores, search_space))"
      ],
      "metadata": {
        "id": "8DbAPkBMFa5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sort them (in reverse this time as the scores are similarity)"
      ],
      "metadata": {
        "id": "f--Ej2RUeQNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scored_candidates = sorted(scored_candidates, key=lambda x: x[0], reverse=True)"
      ],
      "metadata": {
        "id": "JbDFZeAaFqAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And look at the the first five:"
      ],
      "metadata": {
        "id": "BoDCLZBGeVDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_5 = scored_candidates[:5]\n",
        "top_5"
      ],
      "metadata": {
        "id": "9tDATxt8Fr4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yay, the correct answer is the top answer (NSCLC).\n",
        "\n",
        "This is likely fairly fast. If really needed, it could be made to run even faster using appropriate indexing with a library like [pyterrier_pisa](https://github.com/terrierteam/pyterrier_pisa)."
      ],
      "metadata": {
        "id": "E45KwT5_aWxI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dense Vector Search"
      ],
      "metadata": {
        "id": "DxRvkzxMGci_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An alternative approach uses a transformer model. It's more heavy-duty but it doesn't rely on matching the letters of the entity names, so may be able to deal with greater differences.\n",
        "\n",
        "It uses the [SapBERT transformer model](https://huggingface.co/cambridgeltl/SapBERT-from-PubMedBERT-fulltext). The code below loads it and puts it into a [feature-extraction pipeline](https://huggingface.co/tasks/feature-extraction) that can be used to encode text into context vectors."
      ],
      "metadata": {
        "id": "WQvHuAp_el_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "model_name = \"cambridgeltl/SapBERT-from-PubMedBERT-fulltext\"\n",
        "extractor = pipeline(\"feature-extraction\", model=model_name)"
      ],
      "metadata": {
        "id": "9JVWnfLAGdv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can generate context vectors for all the options in our search space with:"
      ],
      "metadata": {
        "id": "1tTbK6XyfIEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_output = extractor(search_space)"
      ],
      "metadata": {
        "id": "MrpwUf3nGhZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We get vectors for every single token in every single text from the search space. We only want the first vector for each option. Let's get those:"
      ],
      "metadata": {
        "id": "Nxfb8WoZfMkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cls_vectors = [ x[0][0] for x in model_output ]"
      ],
      "metadata": {
        "id": "XubBfoE3Iq5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And turn them into a nice numpy array:"
      ],
      "metadata": {
        "id": "KcIWLsxvfVUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "search_vectors = np.array(cls_vectors)\n",
        "\n",
        "search_vectors.shape"
      ],
      "metadata": {
        "id": "vEKnovq9I019"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There were 9 options in the search space and BERT models create vectors that are 768 wide elements wide.\n",
        "\n",
        "Now we get the vector for our mention (n-sclc) that we are searching with:"
      ],
      "metadata": {
        "id": "kRWIJTOxfcgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_output = extractor(mention_text)\n",
        "\n",
        "mention_vector = np.array(model_output[0][0])\n",
        "\n",
        "mention_vector.shape"
      ],
      "metadata": {
        "id": "kLsl3vSRI603"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's a single vector with 768 elements.\n",
        "\n",
        "To get the scores, we calculate the dot-products:"
      ],
      "metadata": {
        "id": "qqWh0k26fqC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "scores = cosine_similarity(search_vectors, mention_vector.reshape(1,-1)) # Need to do .reshape to make it a 2D matrix\n",
        "scores = scores.flatten().tolist() # Get them into a 1D python list"
      ],
      "metadata": {
        "id": "eF9fHKyZJBRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "id": "7_Dk_YYgJF8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we group the scores with all the options from the search space and sort them. Higher is better, so we use `reverse=True` to put the best candidates at the front of the list."
      ],
      "metadata": {
        "id": "zYvdxMTTf0ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scored_candidates = list(zip(scores, search_space))\n",
        "scored_candidates = sorted(scored_candidates, key=lambda x: x[0], reverse=True)"
      ],
      "metadata": {
        "id": "83Sy_yUvJJE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the first five:"
      ],
      "metadata": {
        "id": "yCqUwfBMf_29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_5 = scored_candidates[:5]\n",
        "top_5"
      ],
      "metadata": {
        "id": "o_9gT92AJLP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we're pleased to see that the correct option (NSCLC) is at the top of the list. Notably, lung cancer is second in the list which may be because NSCLC is a type of lung cancer."
      ],
      "metadata": {
        "id": "P8o69z2vgBn8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make it even faster!\n",
        "\n",
        "If you wanted to make the dense vector search faster, you could use a library such as faiss. It can be accelerate with GPUs but we'll just go over the CPU approach here.\n",
        "\n",
        "First install it:"
      ],
      "metadata": {
        "id": "RsjqUbpTJlrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "jypSxr5WZHpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an index of the right size (for vectors with 768 elements) and add in our search vectors:"
      ],
      "metadata": {
        "id": "2kV6wvSOgabk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "\n",
        "index_flat = faiss.IndexFlatIP(768)\n",
        "index_flat.add(search_vectors)"
      ],
      "metadata": {
        "id": "emBhCwePJbVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then run the search with our `mention_vector` and ask for the top five:"
      ],
      "metadata": {
        "id": "2wA7EDN5ggPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores, indices = index_flat.search(mention_vector.reshape(1,768), 5)\n",
        "\n",
        "print(scores)\n",
        "print(indices)"
      ],
      "metadata": {
        "id": "qWfKgR6oK3Oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We actually get the same scores as we did before along with which index they correspond to.\n",
        "\n",
        "We can create our usual ordered candidate list:"
      ],
      "metadata": {
        "id": "ZL1sQWqngqjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scored_candidates = [ (score,search_space[idx]) for score,idx in zip(scores[0],indices[0]) ]"
      ],
      "metadata": {
        "id": "jKq26um2Loni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at the five that were returned:"
      ],
      "metadata": {
        "id": "q3i_Q1iCgxUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scored_candidates"
      ],
      "metadata": {
        "id": "5MFHMjK2LyGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we see that NSCLC is again top with this method"
      ],
      "metadata": {
        "id": "OxhwI3Udgz0q"
      }
    }
  ]
}