{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-P1sR7peBDR"
   },
   "source": [
    "[![Colab Badge Link](https://img.shields.io/badge/open-in%20colab-blue)](https://colab.research.google.com/github/Glasgow-AI4BioMed/tutorials/blob/main/loading_pubmed_xml_files.ipynb)\n",
    "\n",
    "# Loading PubMed XML files\n",
    "\n",
    "This Colab shows some example code of loading a PubMed XML file. These are the large files available through the [bulk download of PubMed](https://pubmed.ncbi.nlm.nih.gov/download/). These files contain title, abstracts and metadata of articles indexed in [PubMed](https://pubmed.ncbi.nlm.nih.gov/).\n",
    "\n",
    "We could get one of the files from the [baseline folder](https://ftp.ncbi.nlm.nih.gov/pubmed/baseline/). But instead, we'll download a sample file (that hopefully will stick around for a while):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i2yG84Cid3Mp",
    "outputId": "b580f2ac-94d2-42a8-e142-68a5c5908602"
   },
   "outputs": [],
   "source": [
    "!wget https://ftp.ncbi.nlm.nih.gov/pubmed/baseline-2024-sample/sample-0001.xml.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mVpN279lXtE"
   },
   "source": [
    "Let's look inside this file. Not that it is gzipped, so we use the `zcat` program to look at the first few lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8xDx3E-eu2Y",
    "outputId": "f2715d93-d7a5-4022-b663-4493b929cba4"
   },
   "outputs": [],
   "source": [
    "!zcat sample-0001.xml.gz | head -n 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3MRLCzP23-q"
   },
   "source": [
    "You can see that the article is surrounded by a `<PubmedArticle>` tag with lots of metadata. We'll want to get every `<PubMedArticle>` block and extract the fields we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_YE4sx3deqWj"
   },
   "outputs": [],
   "source": [
    "filename = 'sample-0001.xml.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "doNyKTUFyjc0"
   },
   "source": [
    "## Basic loading code\n",
    "\n",
    "Let's look at some basic code to load this file with `gzip` and `cElementTree` for XML files. Loading with the `gzip` library means we don't need to decompress the file to process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "onbpuHEkel8I"
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as etree\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fw39-L6VytH3"
   },
   "source": [
    "This code opens the gzipped file and then works through it, one abstract at a time. The files are large so it is generally not a good idea to load all the abstracts into memory in one go.\n",
    "\n",
    "This code extracts on the PubMed identifier (pmid) and the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_6veV_hulh-5",
    "outputId": "98cd76ae-8ffb-4559-b756-cc2b08c12bcf"
   },
   "outputs": [],
   "source": [
    "with gzip.open(filename,'rt',encoding='utf8') as f:\n",
    "  for event, elem in etree.iterparse(f, events=(\"start\", \"end\", \"start-ns\", \"end-ns\")):\n",
    "\n",
    "    # Iterate through the XML file until a <PubmedArticle> tag is closed (which we then process below)\n",
    "    if event == \"end\" and elem.tag == \"PubmedArticle\":\n",
    "\n",
    "      pmid = int(elem.find(\"./MedlineCitation/PMID\").text)\n",
    "      title = elem.find(\"./MedlineCitation/Article/ArticleTitle\").text\n",
    "      print(pmid, title)\n",
    "\n",
    "      elem.clear() # Important for clearing memory as the file is iteratively loaded\n",
    "      break # This break is just for the demonstration so that only the first abstract is loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilF9u1KqzPmu"
   },
   "source": [
    "## More elaborate loading\n",
    "\n",
    "Below is code that extracts a lot of the fields and saving them to a dictionary. We get the title, abstract text and lots of metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZE5pzeqveOCB"
   },
   "outputs": [],
   "source": [
    "with gzip.open(filename,'rt',encoding='utf8') as f:\n",
    "  for event, elem in etree.iterparse(f, events=(\"start\", \"end\", \"start-ns\", \"end-ns\")):\n",
    "\n",
    "    # Iterate through the XML file until a <PubmedArticle> tag is closed (which we then process below)\n",
    "    if event == \"end\" and elem.tag == \"PubmedArticle\":\n",
    "\n",
    "      pmid = int(elem.find(\"./MedlineCitation/PMID\").text)\n",
    "      title = elem.find(\"./MedlineCitation/Article/ArticleTitle\").text\n",
    "\n",
    "      abstract_elems = elem.findall(\"./MedlineCitation/Article/Abstract/AbstractText\")\n",
    "      abstract = \"\\n\".join( \"\".join(e.itertext()) for e in abstract_elems )\n",
    "\n",
    "      publication_types = [ e.text for e in elem.findall(\"./MedlineCitation/Article/PublicationTypeList/PublicationType\") ]\n",
    "\n",
    "      identifier_elems = elem.findall(\"./PubmedData/ArticleIdList/ArticleId\")\n",
    "      identifiers = { e.attrib['IdType']:e.text for e in identifier_elems }\n",
    "\n",
    "      journal_title_elem = elem.find(\"./MedlineCitation/Article/Journal/Title\")\n",
    "      journal_title_iso_elem = elem.find(\"./MedlineCitation/Article/Journal/ISOAbbreviation\")\n",
    "      journal_title = journal_title_elem.text if journal_title_elem is not None else None\n",
    "      journal_title_iso = journal_title_iso_elem.text if journal_title_iso_elem is not None else None\n",
    "\n",
    "      pub_year_elem = elem.find(\"./MedlineCitation/Article/Journal/JournalIssue/PubDate/Year\")\n",
    "      pub_month_elem = elem.find(\"./MedlineCitation/Article/Journal/JournalIssue/PubDate/Month\")\n",
    "      pub_day_elem = elem.find(\"./MedlineCitation/Article/Journal/JournalIssue/PubDate/Day\")\n",
    "      pub_year = pub_year_elem.text if pub_year_elem is not None else None\n",
    "      pub_month = pub_month_elem.text if pub_month_elem is not None else None\n",
    "      pub_day = pub_day_elem.text if pub_day_elem is not None else None\n",
    "\n",
    "      mesh_headings = []\n",
    "      mesh_elems = elem.findall(\"./MedlineCitation/MeshHeadingList/MeshHeading\")\n",
    "      for mesh_elem in mesh_elems:\n",
    "        descriptor_elem = mesh_elem.find(\"./DescriptorName\")\n",
    "        mesh_id = descriptor_elem.attrib[\"UI\"]\n",
    "        name = descriptor_elem.text\n",
    "        major_topic_yn = descriptor_elem.attrib[\"MajorTopicYN\"]\n",
    "\n",
    "        mesh_heading = {'id':mesh_id, 'name':name, 'major_topic':major_topic_yn }\n",
    "        qualifiers = []\n",
    "        qualifier_elems = mesh_elem.findall(\"./QualifierName\")\n",
    "        for qualifier_elem in qualifier_elems:\n",
    "          mesh_id = qualifier_elem.attrib[\"UI\"]\n",
    "          name = qualifier_elem.text\n",
    "          major_topic_yn = qualifier_elem.attrib[\"MajorTopicYN\"]\n",
    "          qualifiers.append( { 'id':mesh_id, 'name':name, 'major_topic':major_topic_yn  } )\n",
    "        mesh_heading['qualifiers'] = qualifiers\n",
    "\n",
    "        mesh_headings.append(mesh_heading)\n",
    "\n",
    "      supplementary_mesh = []\n",
    "      supplementary_mesh_elems = elem.findall(\"./MedlineCitation/SupplMeshList/SupplMeshName\")\n",
    "      for supp_elem in supplementary_mesh_elems:\n",
    "        supp_id = supp_elem.attrib[\"UI\"]\n",
    "        supp_type = supp_elem.attrib[\"Type\"]\n",
    "        supp_name = supp_elem.text\n",
    "        supplementary_mesh.append( {'id':supp_id, 'type':supp_type, 'name':supp_name })\n",
    "\n",
    "      article = {\n",
    "          'pmid':pmid,\n",
    "          'title':title,\n",
    "          'abstract':abstract,\n",
    "          'journal_title':journal_title,\n",
    "          'journal_title_iso':journal_title_iso,\n",
    "          'publication_date': [pub_year, pub_month, pub_day],\n",
    "          'publication_types':publication_types,\n",
    "          'identifiers':identifiers,\n",
    "          'mesh_headings':mesh_headings,\n",
    "          'supplementary_mesh':supplementary_mesh\n",
    "        }\n",
    "\n",
    "      elem.clear() # Important for clearing memory as the file is iteratively loaded\n",
    "      break # This break is just for the demonstration so that only the first abstract is loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySPFEyXdzgSR"
   },
   "source": [
    "And let's see what is extracted for this first article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TSEh1UMMe9IC",
    "outputId": "5183dec5-66fe-4447-9c74-6bc3ce2d6e11"
   },
   "outputs": [],
   "source": [
    "article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-_N1zvWzsJT"
   },
   "source": [
    "There are more metadata fields that could be extracted. You can find more through the DTD documentation available from the [PubMed download page](https://pubmed.ncbi.nlm.nih.gov/download/). There can also be more nuance with some fields, including the abstract which sometimes has section headings in the XML tags or formatting (which are currently ignored)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
